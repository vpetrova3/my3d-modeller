# my3d-modeller
My own 3D modeller built in Python with OpenGL

Notes Taken (as I'm completing the project):
  - OpenGL: graphical application programming interface, which is the standard API for developing graphics applications across platforms. It has two variant: Legacy OpenGL and Modern OpenGL. We will use Legacy OpenGL as it allows us to have the standard linear algebra knowledge required, making the project more readabe and keeping the code size small. 
  - Rendering happens through polygons defined by vertices and normals. So we should specify an object's 4 vertices and the normal of the side.
  - We are using GLUT, bundled with OpenGL, to create the operating system windows and to register any user infterface callcbacks. It's sufficient for the scope of the project.
  - To manage the GLUT and OpenGL settup, we create the Viewer class, and using a single instance of it. It manages window creation and rendering, and it contains the program's main loop. init_interface creates the window that the modeller will be rendered into and specifies the function when the design needs to be rendered.
  - init_opengl sets up the OpenGL state needed for the project. Sets the matrices, enables backface culling, register the light that illuminates the scene, tells OpenGL we'd like color on the objects.
  - init_scene is for the Scene objects, and it places initial nodes to get the user started. init_interaction registers callbacks for user interaction.
  - After initializing the Viewer class, we call glutMainLoop, which transfers program execution to GLUT (a function that never returns). SO callbacks registered on GLUT events will be called when those events occur.
  - Coordinate space: it's an origin point and a set of 3 basis vectors: our know x, y, z axes. Any point in 3 dimensions can be represented as an offset in the x,y,z directions from origin point. The same point has different representations in different coordinate spaces. So any 3D point can be represented in any 3D coordinate space.
  - We will use vectors (difference between 2 x,y,z points) as we will transfrom matrices. In computer graphics, it's convenient to use multiple coordinate spaces for different types of points. Transformation matrices convert points from one coordinate space to another. And to convert a vector v from one coordinate space to another, we multiply by a transformation Matrix M:v' = Mv.
  - So drawing an item to the screen demands convertion between different coordinate spaces. To convert the eye space to homogenous clip space, we use gluPerspective. Then converting to normalised device space and viewport space happens with glViewport. The two matrices are then multiplied together and become the GL_PROJECTION matrix.
  - The science behind it is linear algebra. What we will do is define a matrix that converts points in the model (also called mesh) from the model spaces into the world spaces (model matrix). We also define the view matrix that converts from world space into the eye space. For the project we combine these two to obtain the final output: ModelView matrix:
   *** mesh (w local origin) -> world space (meshes placed in world, world origin) -> eye space (origin at cam, xyz azws line up to camera orientation) then -> homogenous clip space -> normalised device space -> viewport space ***
    - Now how do we render with the viewer: render function begins as it sets up any of the OpenGL state that needs to be done at render time. It initializes the projection matrix via init_view and uses data from the interaction member to initialize the ModelView matrix with the transformation matrix that converts from the scene space to world space. The render function clears the screen with glClear and tells the scene to render itself, then renders the unit grid. Before rendering the grid, we disable OpenGL's lighting. When that happens, OpenGL renders with solid colors, rather than simulating a light source. This way, grid has visual differentation from the scene. Finally, glFLush signals to the graphics driver that we are ready for the buffer tp be flushed and displayed to the screen.
    - We have the rendering piple to handle drawing in the coordinate space, but what are we going to render? We need a data structure to contain the design, and we need to use this ds to render the design. We can self.scene.render() is the render loop. What is this scene: Scene class is the interfrace to the ds we use to represent the design. It abstracts away details of the ds and provides necessary interface functions required to interact with the design (includes functions to render, add items, manipulate items).
    - There is one Scene object, owned by the viewer. The Scene instance keeps a list of all the items in the scene: node_list (it also keeps track of the selected item). Render function on scene calls render on each of the members of node_list.
    - Nodes: in the Scene's render function, we call render on each of the nodes in the Scene's node_list. Node: anything that can be placed in the scene. Node is our abstract base class. Any classes representing objects to be placed in the Scene will inherit from Node. This base class allows us to reason about the scene abstractly. Each type of Node defines its own behavior for rendering itself and for any other interactions. Node keeps note of important data about itself like translation matrix, scale matrix, color, etc. Multiplying the node's scaling to transformation matrix gives the node's model coordinate space to the world coordinate space. Node also stores and axis-aligned bounding box (AABB). Simplest concrete implementation of Node is a primitive (a prim. is a single solid shape that can be added to the scene). For this project the primitives are Cube and Sphere.
    - Rendering nodes is based on the transformation matrices that each node stores. Transformation matrix of a node is the combination of its scaling matrix and its translation matrix. Regardless of the type of node, the first step to rendering is to set the OpenGL ModelView matrix to the transformation matrix to convert from the model coordinate space to the view coordinate space. Once the OpenGL matrices are up to date, we call render_self to tell the node to make the necessary OpenGL calls to draw itself. Then, we undo any changes we made to the OpenGL state for this specific node (restoring and then saving happens with glPushMatrix and glPopMatrix before and after node rendering). Node stores its color, location, and scale and applies these to OpenGL state before rendering.
    - If node is selected, it emits light
    - To render primitives, we use the call lists OpenGL feature (series of OpenGL calls defined once and bundled together under a single name). Calls are dispatched with glCallList(LIST_NAME). Each primitive defines the call list to render.
    - Node class has Scene nodes made up of multiple primitives.
    - We create a class HierarchicalNode (Node containing other nodes). It manages a list of children. render_self for hierarchical nodes calls render_self on each of the child nodes. 
