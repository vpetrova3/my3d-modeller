# my3d-modeller
My own 3D modeller built in Python with OpenGL

Notes Taken (as I'm completing the project):
  - OpenGL: graphical application programming interface, which is the standard API for developing graphics applications across platforms. It has two variant: Legacy OpenGL and Modern OpenGL. We will use Legacy OpenGL as it allows us to have the standard linear algebra knowledge required, making the project more readabe and keeping the code size small. 
  - Rendering happens through polygons defined by vertices and normals. So we should specify an object's 4 vertices and the normal of the side.
  - We are using GLUT, bundled with OpenGL, to create the operating system windows and to register any user infterface callcbacks. It's sufficient for the scope of the project.
  - To manage the GLUT and OpenGL settup, we create the Viewer class, and using a single instance of it. It manages window creation and rendering, and it contains the program's main loop. init_interface creates the window that the modeller will be rendered into and specifies the function when the design needs to be rendered.
  - init_opengl sets up the OpenGL state needed for the project. Sets the matrices, enables backface culling, register the light that illuminates the scene, tells OpenGL we'd like color on the objects.
  - init_scene is for the Scene objects, and it places initial nodes to get the user started. init_interaction registers callbacks for user interaction.
  - After initializing the Viewer class, we call glutMainLoop, which transfers program execution to GLUT (a function that never returns). SO callbacks registered on GLUT events will be called when those events occur.
  - Coordinate space: it's an origin point and a set of 3 basis vectors: our know x, y, z axes. Any point in 3 dimensions can be represented as an offset in the x,y,z directions from origin point. The same point has different representations in different coordinate spaces. So any 3D point can be represented in any 3D coordinate space.
  - We will use vectors (difference between 2 x,y,z points) as we will transfrom matrices. In computer graphics, it's convenient to use multiple coordinate spaces for different types of points. Transformation matrices convert points from one coordinate space to another. And to convert a vector v from one coordinate space to another, we multiply by a transformation Matrix M:v' = Mv.
  - So drawing an item to the screen demands convertion between different coordinate spaces. To convert the eye space to homogenous clip space, we use gluPerspective. Then converting to normalised device space and viewport space happens with glViewport. The two matrices are then multiplied together and become the GL_PROJECTION matrix.
  - The science behind it is linear algebra. What we will do is define a matrix that converts points in the model (also called mesh) from the model spaces into the world spaces (model matrix). We also define the view matrix that converts from world space into the eye space. For the project we combine these two to obtain the final output: ModelView matrix:
   *** mesh (w local origin) -> world space (meshes placed in world, world origin) -> eye space (origin at cam, xyz azws line up to camera orientation) then -> homogenous clip space -> normalised device space -> viewport space ***
    - Now how do we render with the viewer: render function begins as it sets up any of the OpenGL state that needs to be done at render time. It initializes the projection matrix via init_view and uses data from the interaction member to initialize the ModelView matrix with the transformation matrix that converts from the scene space to world space. The render function clears the screen with glClear and tells the scene to render itself, then renders the unit grid. Before rendering the grid, we disable OpenGL's lighting. When that happens, OpenGL renders with solid colors, rather than simulating a light source. This way, grid has visual differentation from the scene. Finally, glFLush signals to the graphics driver that we are ready for the buffer tp be flushed and displayed to the screen.
    - We have the rendering piple to handle drawing in the coordinate space, but what are we going to render? We need a data structure to contain the design, and we need to use this ds to render the design. We can self.scene.render() is the render loop. What is this scene: Scene class is the interfrace to the ds we use to represent the design. It abstracts away details of the ds and provides necessary interface functions required to interact with the design (includes functions to render, add items, manipulate items).
    - There is one Scene object, owned by the viewer. The Scene instance keeps a list of all the items in the scene: node_list (it also keeps track of the selected item). Render function on scene calls render on each of the members of node_list.
    - Nodes: in the Scene's render function, we call render on each of the nodes in the Scene's node_list. Node: anything that can be placed in the scene. Node is our abstract base class. Any classes representing objects to be placed in the Scene will inherit from Node. This base class allows us to reason about the scene abstractly. Each type of Node defines its own behavior for rendering itself and for any other interactions. Node keeps note of important data about itself like translation matrix, scale matrix, color, etc. Multiplying the node's scaling to transformation matrix gives the node's model coordinate space to the world coordinate space. Node also stores and axis-aligned bounding box (AABB). Simplest concrete implementation of Node is a primitive (a prim. is a single solid shape that can be added to the scene). For this project the primitives are Cube and Sphere.
    - Rendering nodes is based on the transformation matrices that each node stores. Transformation matrix of a node is the combination of its scaling matrix and its translation matrix. Regardless of the type of node, the first step to rendering is to set the OpenGL ModelView matrix to the transformation matrix to convert from the model coordinate space to the view coordinate space. Once the OpenGL matrices are up to date, we call render_self to tell the node to make the necessary OpenGL calls to draw itself. Then, we undo any changes we made to the OpenGL state for this specific node (restoring and then saving happens with glPushMatrix and glPopMatrix before and after node rendering). Node stores its color, location, and scale and applies these to OpenGL state before rendering.
    - If node is selected, it emits light
    - To render primitives, we use the call lists OpenGL feature (series of OpenGL calls defined once and bundled together under a single name). Calls are dispatched with glCallList(LIST_NAME). Each primitive defines the call list to render.
    - Node class has Scene nodes made up of multiple primitives.
    - We create a class HierarchicalNode (Node containing other nodes). It manages a list of children. render_self for hierarchical nodes calls render_self on each of the child nodes.
      *** Cube<-Primitive->Sphere <- Node -> HierarchicalNode-> SnowFigure
    - Node objects for a tree data structure. Render function through hierarchical nodes does a DFA throuh the tree. As it traverses, it keeps a stack of ModelView matrices that are used for conversion into world space. At each step, it pushes the current ModelView matrix onto the stack, and when it completes rendering all child noded, it pops the matrix off the stack, leaving parent node's ModelView matrix at top of the stack.
    - Making the Node class this extensible lets us add new shapes to the scene without changing any code for scene manipulation and rendering. Here the Composite design pattern is used as we use the node concept to abstract away the fact that one Scene object may ave many children.
    - User Interaction: we want to change the viewing perspective of the scene. We also need to beable to add new nodes and modify nodes in scene. User Interaction enabled: know when user presses keys or moves mouse. Operating system already knows that and GLUT allows us to register a function to be called when an event occurs.
    - GLUT calls these functions when corresponding keys are pressed (when we know which key user presses, we interpret input and apply intended actions to scene): Logic for these events is in Interaction class. Viewer class has a single instance of it. GLUT callbacl mechanism registers functions when button is pressed (glutMouseFunc). All other functions can be found also: mouse, key.
    - Internal Callbacks: When Interactn instance interprets a user action, it calls self.trigger with a string describing action type. trigger func is a part of a simple callback system that we will use for handling application-level events. init_interaction func in Viewer class registers callbacks on Interaction instance by calling register_callback. When user interface code triggers an event on the scene, Interaction class calls all of the saved callbacks for the specific event.
    - Interaction class (abstract application-level callback system) is a translator between OS events and application-level events. Thus, if we port modeller to another toolkit in addition to GLUT, only Interaction class would change.
    - Callbacks: pick, move, place, rotate_color, scale. Purporese: select node at mouse pointer location, move current selected node to mpl, place a shape of specific type (string) to mpl, rotate color of selected node through list of colors (forward, backwards), scale current selected node up or down (based on parameter). This callback system gives all functionality needed for the project. In a production 3D modeller, however, user interface objects can be destroyed dynamically (register, unregister callbacks for events)
    - Interacting with scene: callback mechanism allows to receive meaningfu info about user input events from Interaction class, we can apply these actions to Scene:
        1. Moving the Scene: Camera motion here happens by transforming the scene, so user input rather moves scene instead of camera. Camera is at [0,0,-15], facing world space origin (can be changed). Revisiting render in Viewer, Interaction state is used to transform OpenGL matrix state before rendering the Scene There are 2 types of interaction: rotation and translation
        2. Rotating the Scene with a Trackball: 
    
